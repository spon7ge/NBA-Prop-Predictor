{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set the account and date range\n",
    "account = \"Underdog__NBA\"\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=90)\n",
    "\n",
    "usernames = [\"Go0sed\"]\n",
    "passwords = [\"Baseball$3\"]\n",
    "num_of_tweets = 75\n",
    "\n",
    "# Convert dates to string format 'YYYY-MM-DD'\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "\n",
    "UserTags, TimeStamps, Tweets_url = [], [], []\n",
    "\n",
    "for user, pw in zip(usernames, passwords):\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    driver.get(f'https://twitter.com/search?q=(from%3A{account})%20until%3A{end_date_str}%20since%3A{start_date_str}&src=typed_query&f=live')\n",
    "\n",
    "    # Wait for the page to load before continuing\n",
    "    sleep(7)\n",
    "\n",
    "    #### LOGIN ######\n",
    "    # Find the username input field using its XPATH and enter a username\n",
    "    username = driver.find_element(By.XPATH, \"//input[@name='text']\")\n",
    "    username.send_keys(user)\n",
    "\n",
    "    # Find the 'Next' button using its XPATH and click it to move to the password field\n",
    "    next_button = driver.find_element(By.XPATH, \"//span[contains(text(),'Next')]\")\n",
    "    next_button.click()\n",
    "\n",
    "    # Wait for the next page to load before continuing\n",
    "    sleep(10)\n",
    "\n",
    "    # Find the password input field using its XPATH and enter a password\n",
    "    password = driver.find_element(By.XPATH, \"//input[@name='password']\")\n",
    "    password.send_keys(pw)\n",
    "\n",
    "    # Find the 'Log in' button using its XPATH and click it to log in\n",
    "    log_in = driver.find_element(By.XPATH, \"//span[contains(text(),'Log in')]\")\n",
    "    log_in.click()\n",
    "\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "    articles = driver.find_elements(By.XPATH, \"//article[@data-testid='tweet']\")\n",
    "\n",
    "    Tweets2, Tweets = [], []\n",
    "\n",
    "    begin = time.time()\n",
    "\n",
    "    with tqdm(total=num_of_tweets, desc=\"Extracting tweets\", unit=\"tweet\") as pbar:\n",
    "        while True:\n",
    "            for article in articles:\n",
    "                try:\n",
    "                    Tweet = article.find_element(By.XPATH, \".//div[@data-testid='tweetText']\").text\n",
    "                    if ' out' in Tweet.lower() or 'miss rest of season' in Tweet.lower() or 'indefinitely' in Tweer.lower() or 'restriction' in Tweet.lower() or 'late scratch' in Tweet.lower() or ' doubtful' in Tweet.lower():\n",
    "                        Tweets.append(Tweet)\n",
    "\n",
    "                        UserTag = article.find_element(By.XPATH, \".//div[@data-testid='User-Name']\").text\n",
    "                        UserTags.append(UserTag)\n",
    "\n",
    "                        TimeStamp = article.find_element(By.XPATH, \".//time\").get_attribute('datetime')\n",
    "                        TimeStamps.append(TimeStamp)\n",
    "\n",
    "                        Tweets_url.append((Tweet, TimeStamp.split('T')[0]))\n",
    "                        pbar.update(1)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            Tweets2 = list(set(Tweets))\n",
    "\n",
    "            if len(Tweets2) >= num_of_tweets:\n",
    "                print(len(Tweets2))\n",
    "                break\n",
    "\n",
    "            driver.execute_script('window.scrollTo(0,document.body.scrollHeight);')\n",
    "            time.sleep(3)\n",
    "            articles = driver.find_elements(By.XPATH, \"//article[@data-testid='tweet']\")\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"Scraping done for username: {user}\")\n",
    "    print(\"Time taken: \", end - begin)\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "# Convert the collected data to a DataFrame and save it to a CSV file\n",
    "tweet, ts = zip(*Tweets_url)\n",
    "df = pd.DataFrame({\"tweetContent\": tweet, \"timeStamp\": ts})\n",
    "df.to_csv(r'C:\\Users\\alexg\\OneDrive\\Documents\\Prize-Picks-Prop-Predictor\\Underdog_Scrape.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
