{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# API settings\n",
    "API_KEY = os.environ.get('HISTORICAL_API_KEY')\n",
    "BASE_URL = \"https://api.the-odds-api.com/v4/historical/sports/basketball_nba\"\n",
    "\n",
    "# Function to get formatted date string\n",
    "def get_date_string(date):\n",
    "    return date.strftime('%Y-%m-%dT21:00:00Z')  # 5:00 PM ET\n",
    "\n",
    "def get_csv_date(date):\n",
    "    return date.strftime('%m_%d_%Y')\n",
    "\n",
    "# Start with 30 days of data\n",
    "start_date = datetime(2024, 12, 16)  # Adjust start date as needed\n",
    "days_to_collect = 15\n",
    "\n",
    "all_days_props = []  # Store all days' data\n",
    "\n",
    "for day in range(days_to_collect):\n",
    "    current_date = start_date + timedelta(days=day)\n",
    "    DATE = get_date_string(current_date)\n",
    "    event_ids = []\n",
    "    \n",
    "    print(f\"\\nFetching data for {current_date.date()}\")\n",
    "    \n",
    "    # 1) List events for the day\n",
    "    events_resp = requests.get(\n",
    "        f\"{BASE_URL}/events\",\n",
    "        params={\n",
    "            \"apiKey\": API_KEY,\n",
    "            \"date\": DATE\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if events_resp.status_code != 200:\n",
    "        print(f\"Error fetching events: HTTP {events_resp.status_code}\")\n",
    "        print(events_resp.text)\n",
    "        continue\n",
    "        \n",
    "    # Parse JSON and get events\n",
    "    resp_json = events_resp.json()\n",
    "    events = resp_json if isinstance(resp_json, list) else resp_json.get(\"data\", [])\n",
    "    \n",
    "    # Get event IDs\n",
    "    for ev in events:\n",
    "        ev_id = ev.get(\"id\") or ev.get(\"event_id\")\n",
    "        event_ids.append(ev_id)\n",
    "        print(f\"Found game: {ev.get('away_team')} at {ev.get('home_team')}\")\n",
    "    \n",
    "    # 2) Get odds for each event\n",
    "    day_props = []  # Store this day's data\n",
    "    \n",
    "    for id in event_ids:\n",
    "        url = f'{BASE_URL}/events/{id}/odds'\n",
    "        \n",
    "        params = {\n",
    "            'apiKey': API_KEY,\n",
    "            'date': DATE,\n",
    "            'regions': 'us_dfs',\n",
    "            'markets': 'player_points,player_rebounds,player_assists',\n",
    "            'oddsFormat': 'american',\n",
    "            'dateFormat': 'iso'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            props = []\n",
    "            \n",
    "            game_info = {\n",
    "                'home_team': data['data']['home_team'],\n",
    "                'away_team': data['data']['away_team'],\n",
    "                'game_id': id,\n",
    "                'commence_time': data['data']['commence_time']\n",
    "            }\n",
    "            \n",
    "            for bookmaker in data['data']['bookmakers']:\n",
    "                for market in bookmaker['markets']:\n",
    "                    if market['key'] in ['player_points', 'player_rebounds', 'player_assists']:\n",
    "                        for outcome in market['outcomes']:\n",
    "                            prop_dict = {\n",
    "                                'player': outcome['description'],\n",
    "                                'market': market['key'],\n",
    "                                'bookmaker': bookmaker['title'],\n",
    "                                'side': outcome['name'],\n",
    "                                'line': outcome['point'],\n",
    "                                'price': outcome['price'],\n",
    "                                **game_info\n",
    "                            }\n",
    "                            props.append(prop_dict)\n",
    "            \n",
    "            if props:\n",
    "                day_props.extend(props)\n",
    "        else:\n",
    "            print(f'Failed to get odds for game {id}: status_code {response.status_code}')\n",
    "        \n",
    "        # Add delay to avoid hitting API rate limits\n",
    "        time.sleep(0.1)  # 100ms delay between requests\n",
    "    \n",
    "    # Create DataFrame for this day\n",
    "    if day_props:\n",
    "        df = pd.DataFrame(day_props)\n",
    "        \n",
    "        # Save individual day's data\n",
    "        csv_date = get_csv_date(current_date)\n",
    "        df.to_csv(f'CSV_FILES/HISTORICAL_ODDS/{csv_date}.csv', index=False)\n",
    "        \n",
    "        all_days_props.extend(day_props)\n",
    "        print(f\"Saved data for {current_date.date()} - {len(day_props)} props collected\")\n",
    "    \n",
    "    # Add delay between days\n",
    "    time.sleep(1)  # 1 second delay between days\n",
    "\n",
    "# Create final combined DataFrame\n",
    "if all_days_props:\n",
    "    final_df = pd.DataFrame(all_days_props)\n",
    "    \n",
    "    # Save combined data\n",
    "    final_df.to_csv('CSV_FILES/HISTORICAL_ODDS/ALL_HISTORICAL_ODDS.csv', index=False)\n",
    "    print(f\"\\nCompleted! Total props collected: {len(all_days_props)}\")\n",
    "else:\n",
    "    print(\"No data was collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 01_01_2025.csv\n",
      "Reading 01_02_2025.csv\n",
      "Reading 01_03_2025.csv\n",
      "Reading 01_04_2025.csv\n",
      "Reading 01_05_2025.csv\n",
      "Reading 01_06_2025.csv\n",
      "Reading 01_07_2025.csv\n",
      "Reading 01_08_2025.csv\n",
      "Reading 01_09_2025.csv\n",
      "Reading 01_10_2025.csv\n",
      "Reading 01_11_2025.csv\n",
      "Reading 01_12_2025.csv\n",
      "Reading 01_13_2025.csv\n",
      "Reading 10_22_2024.csv\n",
      "Reading 10_23_2024.csv\n",
      "Reading 10_24_2024.csv\n",
      "Reading 10_25_2024.csv\n",
      "Reading 10_26_2024.csv\n",
      "Reading 10_27_2024.csv\n",
      "Reading 10_28_2024.csv\n",
      "Reading 10_29_2024.csv\n",
      "Reading 10_30_2024.csv\n",
      "Reading 10_31_2024.csv\n",
      "Reading 11_01_2024.csv\n",
      "Reading 11_02_2024.csv\n",
      "Reading 11_03_2024.csv\n",
      "Reading 11_04_2024.csv\n",
      "Reading 11_05_2024.csv\n",
      "Reading 11_06_2024.csv\n",
      "Reading 11_07_2024.csv\n",
      "Reading 11_08_2024.csv\n",
      "Reading 11_09_2024.csv\n",
      "Reading 11_10_2024.csv\n",
      "Reading 11_11_2024.csv\n",
      "Reading 11_12_2024.csv\n",
      "Reading 11_13_2024.csv\n",
      "Reading 11_14_2024.csv\n",
      "Reading 11_15_2024.csv\n",
      "Reading 11_16_2024.csv\n",
      "Reading 11_17_2024.csv\n",
      "Reading 11_18_2024.csv\n",
      "Reading 11_19_2024.csv\n",
      "Reading 11_20_2024.csv\n",
      "Reading 11_21_2024.csv\n",
      "Reading 11_22_2024.csv\n",
      "Reading 11_23_2024.csv\n",
      "Reading 11_24_2024.csv\n",
      "Reading 11_25_2024.csv\n",
      "Reading 11_26_2024.csv\n",
      "Reading 11_27_2024.csv\n",
      "Reading 11_28_2024.csv\n",
      "Reading 11_29_2024.csv\n",
      "Reading 11_30_2024.csv\n",
      "Reading 12_01_2024.csv\n",
      "Reading 12_02_2024.csv\n",
      "Reading 12_03_2024.csv\n",
      "Reading 12_04_2024.csv\n",
      "Reading 12_05_2024.csv\n",
      "Reading 12_06_2024.csv\n",
      "Reading 12_07_2024.csv\n",
      "Reading 12_08_2024.csv\n",
      "Reading 12_09_2024.csv\n",
      "Reading 12_10_2024.csv\n",
      "Reading 12_11_2024.csv\n",
      "Reading 12_12_2024.csv\n",
      "Reading 12_13_2024.csv\n",
      "Reading 12_14_2024.csv\n",
      "Reading 12_15_2024.csv\n",
      "Reading 12_16_2024.csv\n",
      "Reading 12_17_2024.csv\n",
      "Reading 12_18_2024.csv\n",
      "Reading 12_19_2024.csv\n",
      "Reading 12_20_2024.csv\n",
      "Reading 12_21_2024.csv\n",
      "Reading 12_22_2024.csv\n",
      "Reading 12_23_2024.csv\n",
      "Reading 12_24_2024.csv\n",
      "Reading 12_25_2024.csv\n",
      "Reading 12_26_2024.csv\n",
      "Reading 12_27_2024.csv\n",
      "Reading 12_28_2024.csv\n",
      "Reading 12_29_2024.csv\n",
      "Reading 12_30_2024.csv\n",
      "Reading 12_31_2024.csv\n",
      "\n",
      "Total rows in combined dataset: 42932\n",
      "Saved combined data to CSV_FILES/HISTORICAL_ODDS/ALL_HISTORICAL_ODDS.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Path to your historical odds directory\n",
    "historical_odds_path = 'CSV_FILES/HISTORICAL_ODDS/'\n",
    "\n",
    "# Get all CSV files in the directory\n",
    "csv_files = glob.glob(os.path.join(historical_odds_path, '*.csv'))\n",
    "\n",
    "# Filter out the ALL_HISTORICAL_ODDS.csv if it exists\n",
    "csv_files = [f for f in csv_files if 'ALL_HISTORICAL_ODDS.csv' not in f]\n",
    "\n",
    "# List to store all dataframes\n",
    "all_dfs = []\n",
    "\n",
    "# Read each CSV file and append to the list\n",
    "for file in csv_files:\n",
    "    print(f\"Reading {os.path.basename(file)}\")\n",
    "    df = pd.read_csv(file)\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes\n",
    "if all_dfs:\n",
    "    final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(f\"\\nTotal rows in combined dataset: {len(final_df)}\")\n",
    "    \n",
    "    # Save the combined dataset\n",
    "    output_path = os.path.join(historical_odds_path, 'ALL_HISTORICAL_ODDS.csv')\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved combined data to {output_path}\")\n",
    "else:\n",
    "    print(\"No CSV files found to combine\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
